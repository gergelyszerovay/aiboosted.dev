{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e7b6ae6-6931-4da3-913f-6b80b38a572a",
   "metadata": {},
   "source": [
    "## [AIBoosted.dev](https://aiboosted.dev)\n",
    "### A basic Langchain.js chain with prompt template, structured JSON output and OpenAI LLMs\n",
    "\n",
    "In this example, in this example I show you a basic LLM chain, that can review and improve a text. We create a basic LLM chain using LangChain.js. \n",
    "We use prompt templates, and ask for structured JSON output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edceb05-9068-4822-abad-9a0429e47cbb",
   "metadata": {},
   "source": [
    "**To run this notebook locally, set up your own local Jupyter dev environment: [Create an AI prototyping environment using Jupyter Lab IDE with Typescript, LangChain.js and Ollama for rapid AI prototyping](https://www.aiboosted.dev/p/install-jupyter-lab-deno-typescript-prototyping)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f51feb-fee6-4c4c-ac47-3fa2c658f68d",
   "metadata": {},
   "source": [
    "You have to create a `.env` file with an [OpenAI API key](https://platform.openai.com/api-keys):\n",
    "\n",
    "```\n",
    "OPENAI_API_KEY=[your OpenAI API key]\n",
    "```\n",
    "\n",
    "The following code cell reads the `.env` file and sets the environment variables, so Langchain can use the OpenAI API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f454738-e7b4-457f-89ac-adb8a4a217b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Module: null prototype] {  }"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// auto-load .env\n",
    "import \"https://deno.land/std@0.215.0/dotenv/load.ts\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf62745c-bcb9-4622-a1d5-d2bcd63e26c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ChatOpenAI, OpenAI } from \"npm:@langchain/openai@~0.1\";\n",
    "import { DynamicStructuredTool } from \"npm:@langchain/core@~0.2/tools\";\n",
    "import { PromptTemplate } from \"npm:@langchain/core@~0.2/prompts\";\n",
    "import { z } from \"npm:zod\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e0e5b17-75a2-43df-a440-7f3d30f2ff67",
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    " * Reviews and corrects the input text using OpenAI's GPT-4o model.\n",
    " * \n",
    " * @param instruction - Instructions to be given to the model.\n",
    " * @param inputText - The text to be reviewed and corrected.\n",
    " * @returns - The reviewed and corrected text, or undefined if the response is invalid.\n",
    " */\n",
    "async function reviewTextOpenAI(instruction: string, inputText: string): Promise<string | undefined> {\n",
    "  // Create a prompt template using the provided instruction and input text\n",
    "  const prompt = PromptTemplate.fromTemplate(\n",
    "`{instruction}\n",
    "---\n",
    "{inputText}`);\n",
    "  \n",
    "  // Initialize the OpenAI chat model with specified options\n",
    "  const llm = new ChatOpenAI({\n",
    "    modelName: \"gpt-4o\", // Use the GPT-4 model\n",
    "    verbose: false, // Disable verbose logging\n",
    "  });\n",
    "\n",
    "  // Define the schema for the model's output, it contains the reviewed text  \n",
    "  const reviewedTextSchema = z.object({\n",
    "    reviewedText: z.string().describe(\"The reviewed text.\") // The reviewed text must be a string\n",
    "  });\n",
    "  type ReviewedTextSchema = z.infer<typeof reviewedTextSchema>; // Infer the TypeScript type from the Zod schema\n",
    "\n",
    "  // We expect structured JSON output, we achieve this using OpenAI's function calling feature\n",
    "  const llmWithStructuredOutput = llm.withStructuredOutput(reviewedTextSchema, {\n",
    "    method: \"functionCalling\",\n",
    "    name: \"withStructuredOutput\"\n",
    "  });  \n",
    "  \n",
    "  // Create a processing chain combining the prompt and the LLM\n",
    "  const chain = prompt.pipe(llmWithStructuredOutput);\n",
    "\n",
    "  // Invoke the chain with the instruction and input text, and wait for the response\n",
    "  const response: ReviewedTextSchema = await chain.invoke({ instruction, inputText });\n",
    "\n",
    "  // Return the reviewed text if present in the response, otherwise undefined  \n",
    "  return response?.reviewedText;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c6b43fc-d343-4204-8ce8-2c90442c4aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How to stay relevant as a developer in the world of AI?\n"
     ]
    }
   ],
   "source": [
    "// Define the instruction and input text for the prompt\n",
    "const instruction = \"Fix the grammar issues in the following text.\";\n",
    "const inputText = \"How to stays relevant as the developer in the world of ai?\";\n",
    "\n",
    "// show the reviewed text returned by the LLM\n",
    "console.log(await reviewTextOpenAI(instruction, inputText));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nb_converter": "script",
   "pygments_lexer": "typescript",
   "version": "5.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
