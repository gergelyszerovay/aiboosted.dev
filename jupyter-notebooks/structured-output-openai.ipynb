{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "426f79c6-c12e-4286-beef-0d863ed3481d",
   "metadata": {},
   "source": [
    "## [AIBoosted.dev](https://aiboosted.dev)\n",
    "### Structured JSON LLM model output using Typescript, Langchain and OpenAI\n",
    "\n",
    "In this example, we ask the LLM to review our text, and return the response as JSON, with the following data structure: `{ \"reviewedText\": \"the reviewed text\" }`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3adad8-8342-4d39-9a23-c3a8ff326770",
   "metadata": {},
   "source": [
    "**To run this notebook locally, set up your own local Jupyter dev environmet: [Create an AI prototyping environment using Jupyter Lab IDE with Typescript, LangChain.js and Ollama for rapid AI prototyping](https://www.aiboosted.dev/p/install-jupyter-lab-deno-typescript-prototyping)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1c9feb-6fd1-434c-ab5f-e162a10e69fa",
   "metadata": {},
   "source": [
    "You have to create a `.env` file with an OpenAI API key:\n",
    "\n",
    "```\n",
    "OPENAI_API_KEY=[your OpenAI API key]\n",
    "```\n",
    "\n",
    "The following code cell reads the `.env` file and sets the environment variables, so Langchain can use the OpenAI API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47837bad-e9e2-4789-a1e6-e3673809e836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Module: null prototype] {  }"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// auto-load .env\n",
    "import \"https://deno.land/std@0.215.0/dotenv/load.ts\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adeda532-e4d7-4a3b-981f-ecd790360d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ChatOpenAI, OpenAI } from \"npm:@langchain/openai@~0.1\";\n",
    "import { DynamicStructuredTool } from \"npm:@langchain/core@~0.2/tools\";\n",
    "import { PromptTemplate } from \"npm:@langchain/core@~0.2/prompts\";\n",
    "import { z } from \"npm:zod\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49ea9a09-d6ca-4f92-b7f1-6dfc70b1c185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How to stay relevant as a developer in the world of AI?\n"
     ]
    }
   ],
   "source": [
    "/**\n",
    " * Reviews and corrects the input text using OpenAI's GPT-4o model.\n",
    " * \n",
    " * @param instruction - Instructions to be given to the model.\n",
    " * @param inputText - The text to be reviewed and corrected.\n",
    " * @returns - The reviewed and corrected text, or undefined if the response is invalid.\n",
    " */\n",
    "async function reviewTextOpenAI(instruction: string, inputText: string): Promise<string | undefined> {\n",
    "  // Create a prompt template using the provided instruction and input text\n",
    "  const prompt = PromptTemplate.fromTemplate(\n",
    "`{instruction}\n",
    "---\n",
    "{inputText}`);\n",
    "  \n",
    "  // Initialize the OpenAI chat model with specified options\n",
    "  const llm = new ChatOpenAI({\n",
    "    modelName: \"gpt-4o\", // Use the GPT-4 model\n",
    "    verbose: false, // Disable verbose logging\n",
    "  });\n",
    "\n",
    "  // Define the schema for the model's output, it contains the reviewed text  \n",
    "  const reviewedTextSchema = z.object({\n",
    "    reviewedText: z.string().describe(\"The reviewed text.\") // The reviewed text must be a string\n",
    "  });\n",
    "  type ReviewedTextSchema = z.infer<typeof reviewedTextSchema>; // Infer the TypeScript type from the Zod schema\n",
    "\n",
    "  // We expect structured JSON output, we achieve this using OpenAI's function calling feature\n",
    "  // More details: https://js.langchain.com/v0.2/docs/how_to/structured_output/\n",
    "  const llmWithStructuredOutput = llm.withStructuredOutput(reviewedTextSchema, {\n",
    "    method: \"functionCalling\",\n",
    "    name: \"withStructuredOutput\"\n",
    "  });  \n",
    "  \n",
    "  // Create a processing chain combining the prompt and the LLM\n",
    "  // More details: https://js.langchain.com/v0.2/docs/how_to/sequence\n",
    "  const chain = prompt.pipe(llmWithStructuredOutput);\n",
    "\n",
    "  // Invoke the chain with the instruction and input text, and wait for the response\n",
    "  const response = await chain.invoke({ instruction, inputText });\n",
    "\n",
    "  // Return the reviewed text if present in the response, otherwise undefined  \n",
    "  return response?.reviewedText;\n",
    "}\n",
    "\n",
    "// we specify the inputs for the prompt\n",
    "const instruction = \"Fix the grammar issues in the following text.\";\n",
    "const inputText = \"How to stays relevant as the developer in the world of ai?\";\n",
    "\n",
    "// we show the reviewed text returned by the LLM\n",
    "console.log(await reviewTextOpenAI(instruction, inputText));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nb_converter": "script",
   "pygments_lexer": "typescript",
   "version": "5.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
